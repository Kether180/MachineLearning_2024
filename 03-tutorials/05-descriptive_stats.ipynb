{
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": "py",
      "mimetype": "text/x-python",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "code",
      "id": "css_setup",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "HTML(f\"\"\"\n",
        "<style>\n",
        "@import \"https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css\";\n",
        "</style>\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ie5Z6PjQu7HFEgVHyjIck",
      "metadata": {},
      "source": [
        "# Data wrangling and statistics\n",
        "This tutorial covers essential concepts in descriptive statistics and their implementation in python. \n",
        "The tutorial includes:\n",
        "1. Initial Data Examination\n",
        "2. Descriptive Statistics\n",
        "3. Visualizations\n",
        "\n",
        "To fulfill the goals of this tutorial, we will make use of the Titanic dataset, which provides information about passengers on board the RMS Titanic. Run the code cells below to load the dataset, and the necessary libraries for obtaining descriptive statistics.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "Kzt4Z7VOFGB3p_tB4Ykoz",
      "metadata": {},
      "source": [
        "# import numpy\n",
        "import numpy as np\n",
        "# library for plotting and importing the data\n",
        "import seaborn as sns\n",
        "# library for specific stiatistics\n",
        "from scipy.stats import skew, kurtosis\n",
        "# library for manipulating and analysing data \n",
        "import pandas as pd\n",
        "# Load and filter the titanic dataset\n",
        "titanic = sns.load_dataset('titanic')\n",
        "titanic = titanic[['survived','age', 'sex', 'fare', 'deck', 'class', 'embark_town','alone']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "_W599Vw4YURSKSoSLa_oD",
      "metadata": {},
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "rY_aqpnyFmvLL5pM1z_F0",
      "metadata": {},
      "source": [
        "# for display clarity \n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "04UlV6mvw5K92MDkezpYp",
      "metadata": {},
      "source": [
        "## Initial Data Examination\n",
        "The first steps is to get a quick overview of your dataset. The `head()`\n",
        " function shows the initial rows of the dataset, providing a brief overview of what the data looks like. This initial examination helps you understand how the data is organized (sometimes even showing missing values) and make informed decisions about further approaches.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "uGC6ydteAr3P_rc-8oc_E",
      "metadata": {},
      "source": [
        "print(titanic.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "X3qNq3rM488DDso6DkHqZ",
      "metadata": {},
      "source": [
        "As illustrated in the output, this version of the dataset consists of 8 variables:\n",
        "1. `survived`\n",
        ": Indicates whether the passenger survived (0 = No, 1 = Yes).\n",
        "\n",
        "2. `age`\n",
        ": Age of the passenger.\n",
        "\n",
        "3. `sex`\n",
        ": Gender of the passenger.\n",
        "\n",
        "4. `fare`\n",
        ": Fare paid for the ticket.\n",
        "\n",
        "5. `class`\n",
        ": Equivalent to pclass but as a categoriacal data type.\n",
        "\n",
        "6. `deck`\n",
        ": Deck where the passenger's cabin was located.\n",
        "\n",
        "7. `embark_town`\n",
        ": Town where the passenger embarked.\n",
        "\n",
        "8. `alone`\n",
        ": Indicates whether the passenger was traveling alone.\n",
        "\n",
        "\n",
        "Additionally, the output reveals missing values (NaN), which will be relevant later in this tutorial. \n",
        "### Dimensionality\n",
        "Executing the code cell below returns a tuple with the dimensions of the dataset (rows, columns), by making use of the `.shape`\n",
        " attribute:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "V_Gexk1Tu3UwseoSETuQx",
      "metadata": {},
      "source": [
        "print(titanic.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "u2Q4ScC3scYL0oJbl12QZ",
      "metadata": {},
      "source": [
        "### Data types and Structures\n",
        "Data types refer to the format in which data is stored. In the cell below the `.dtypes`\n",
        " attribute is used to access the data types of the features in the dataset:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "QNM7LG0Qx8HXohAUMW2gP",
      "metadata": {},
      "source": [
        "print(titanic.dtypes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5ZEi4JjA5-1fdJvfO6_6d",
      "metadata": {},
      "source": [
        "The generic Python object data type is called `object`\n",
        ". Objects can consist of various types, such as strings, lists, dictionaries, or even custom objects. \n",
        "## Descriptive Statistics\n",
        "Descriptive statistics are a fundamental component in understanding a dataset, as they provide a concise summary of its main characteristics by summarizing its central tendencies, variability, and distribution. \n",
        "### Summary Statistics\n",
        "When examining a dataset, it's common to encounter two types of variables: numerical and categorical. Numerical variables represent quantities or measurements, while categorical variables represent categories or labels. To gain meaningful insights, numerical and categorical variables are summarized separately. \n",
        "**Numerical summary**\n",
        "Statistics of numerical variables include quantities such as\n",
        "- mean (average)\n",
        "- median (middle value)\n",
        "- mode (most frequent value)\n",
        "- range (difference between the maximum and minimum values)\n",
        "- quartiles (for assessing spread and distribution)\n",
        "- variance and standard deviation (both are measures of data dispersion)\n",
        "- skewness (distribution asymmetry measure) \n",
        "- kurtosis (tail thickness of distributions). \n",
        "\n",
        "The `describe()`\n",
        " function from the pandas library, and the `skew()`\n",
        " and `kurtosis()`\n",
        " functions from the scipy library are used in the cell below to calculate the statistics.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "dquKrOyFb_9lZor7GWPBL",
      "metadata": {},
      "source": [
        "# Get summary statistics for numerical columns\n",
        "numerical_summary = titanic.describe()\n",
        "\n",
        "# Rename the \"50%\" row to \"median\" for clarity\n",
        "numerical_summary = numerical_summary.rename(index={'50%': 'median'})\n",
        "\n",
        "# Calculate the range and add it as a new row\n",
        "numerical_columns = titanic.select_dtypes(include=[np.number])\n",
        "range_values = numerical_columns.max(numeric_only=True) - numerical_columns.min(numeric_only=True)\n",
        "numerical_summary.loc['range'] = range_values\n",
        "\n",
        "# Find the mode \n",
        "numerical_summary.loc['mode'] = titanic.select_dtypes(include=[np.number]).mode().iloc[0]\n",
        "\n",
        "# Calculate variance, skewness, and kurtosis and add as new rows to summary\n",
        "numerical_columns = titanic.select_dtypes(include=[np.number])\n",
        "variance_values = numerical_columns.var()\n",
        "skewness_values = skew(numerical_columns, axis=0)\n",
        "kurtosis_values = kurtosis(numerical_columns, axis=0)\n",
        "numerical_summary.loc['variance'] = variance_values\n",
        "numerical_summary.loc['skewness'] = skewness_values\n",
        "numerical_summary.loc['kurtosis'] = kurtosis_values\n",
        "\n",
        "# Reorder the rows for clarity\n",
        "numerical_summary = numerical_summary.reindex(['count', 'mean', 'median', '25%', '75%','mode', 'min', 'max','range', 'std','variance','skewness','kurtosis'])\n",
        "\n",
        "# Print the numerical summary statistics\n",
        "print(numerical_summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "l3jnvzSDmvVEIgUaG3nIJ",
      "metadata": {},
      "source": [
        "Observe a skewness and kurtosis value of NaN for the `age`\n",
        " variable. As you progress through the tutorial, you will discover that this variable includes missing values, resulting in an inaccurate calculation of these statistical measures.\n",
        "**Categorical summary**\n",
        "Categorical variables require different types of summary statistics and include \n",
        "- counts\n",
        "- percentages\n",
        "- frequencies\n",
        "- most common values\n",
        "\n",
        "for each category. The cell below uses the `describe()`\n",
        " function to obtain statistics of categorical variables:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "eE1sAUt6sTfHrIZbSO2RE",
      "metadata": {},
      "source": [
        "# Get summary statistics for categorical columns\n",
        "categorical_summary = titanic.describe(include='category')\n",
        "\n",
        "# For clarity rename top to mode, as the two are equivalent\n",
        "categorical_summary = categorical_summary.rename(index={'top': 'mode'})\n",
        "\n",
        "print(categorical_summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "pgtZ8suiWxqJbqWFWIFUL",
      "metadata": {},
      "source": [
        "The statistics of the categorical variables do not provide insight into the distribution of each category, and therefore no insights into class imbalances. The cell below calculates the frequency of occurrence of each unique category within the dataset:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "8fwfOXLurtl3hvqamqgDI",
      "metadata": {},
      "source": [
        "# count the number of observations belonging to each category\n",
        "category_counts = titanic.select_dtypes(include='category').apply(lambda col: col.value_counts())\n",
        "# this is only for display purposes\n",
        "category_counts = category_counts.reindex(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'First', 'Second', 'Third'])\n",
        "print(category_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "wNtW6GBtP4sjhgLRtCR7R",
      "metadata": {},
      "source": [
        "The output shows that there is an imbalance in the categorical variables (varying number of observation for each class). Issues about imbalances will become important later in the course, when discussing classification. \n",
        "### Covariance\n",
        "Covariance is a measure of how much random variables co-vary (vary together, like the age of a person and the fare price paid by a passenger). Mathematically, the covariance between two variables $x$ and $y$ is defined as: \n",
        "\n",
        "$$\n",
        "\\text{Cov}(x, y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n",
        "$$\n",
        "where $n$ is the number of samples, $\\bar{x}$ and $\\bar{y}$ are the means of the random variables, and $x_i$ and $y_i$ refer to the specific data values of the random variables. The code cell below contains an implementation of the covariance calculation:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "TBQRSegb4M0CGWyxbeFPy",
      "metadata": {},
      "source": [
        "def custom_covariance(x, y):\n",
        "    n = len(x)\n",
        "    mean_x = np.mean(x)\n",
        "    mean_y = np.mean(y)\n",
        "    \n",
        "    covariance = np.sum((x - mean_x) * (y - mean_y)) / (n - 1)\n",
        "    return covariance\n",
        "\n",
        "\n",
        "print(custom_covariance(titanic['age'], titanic['fare']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "Dr3bgrc-eRFsiLZ4PZcrS",
      "metadata": {},
      "source": [
        "A positive covariance value indicates that two variables tend to move in the same direction, while a negative covariance value indicates that they tend to move in opposite directions. The magnitude of the covariance value is directly influenced by the scales of the variables involved. For example the variables `age`\n",
        " and `fare`\n",
        " have different units of measurement, which can make it challenging to compare covariances across the pair of variables.\n",
        "### Correlation\n",
        "Measures of correlation standardizes the covariance by transforming it into the range between -1 and 1. Pearson's $r$ is defined as:\n",
        "\n",
        "$$\n",
        "\\text{r} = \\frac{\\text{Cov}(x, y)}{\\sigma_x \\cdot \\sigma_y}\n",
        "$$\n",
        "where $\\sigma_x$ and $\\sigma_y$ are the standard deviations of each random variable involved. \n",
        "Covariance and correlation are similar statistical measures, as both quantify how two variables co-vary. Using the values of the covariance when the two variables have different units of measurment makes interpretation difficult. Standardization in correlation attempts to make this easier. The absolute value of the correlation coefficient indicates the strength of the relationship, with the strength increasing as the values get closer to 1 and -1. The sign of the correlation coefficient (+ or -) indicates the direction of the relationship. A positive correlation means that when one variable increases, the other increases at a constant rate, while a negative correlation means that when one variable increases, the other decreases at a constant rate. A correlation of 0 indicates no linear relationship between two variables.\n",
        "The code cell below calculates Pearson's correlation between `survived`\n",
        " and `fare`\n",
        " variables:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "feHnLp5mwsBgI3RE9KvNr",
      "metadata": {},
      "source": [
        "# get the covariance between\n",
        "num = custom_covariance(titanic['survived'], titanic['fare'])\n",
        "# get all standard deviation for x (survived)\n",
        "sigma_x =np.sum((np.std(titanic['survived'])))\n",
        "# get all standard deviation for y (fare)\n",
        "sigma_y = (np.sum((np.std(titanic['fare']))))\n",
        "\n",
        "print(num/(sigma_x*sigma_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "j0WnKrwLv_PrUPueEmxT6",
      "metadata": {},
      "source": [
        "Correlation between multiple variables result in a correlation matrix. The cell below calculates multivariate correlation for the Titanic dataset using the `corr`\n",
        " function from pandas:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "3wpyJcN1YLOyBPBiSbrOL",
      "metadata": {},
      "source": [
        "# Calculate the pairwise correlation matrix\n",
        "correlation_matrix = numerical_columns.corr()\n",
        "\n",
        "print(correlation_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "r22-_ihhUes1fZXjF-Fzs",
      "metadata": {},
      "source": [
        "### Missing Data\n",
        "Missing data refers to absent or incomplete values in a dataset. It's common to encounter missing data due to various reasons such as data collection errors, sensor failures, or simply because certain information was not collected for some observations. Dealing with missing data is a crucial step in data preprocessing, as it can significantly impact the accuracy and reliability of any analysis or modeling performed on the dataset. The code cell below identifies the number of missing values for each variable in the dataset, by calling the `isna()`\n",
        " function: \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "_5j9bmw-6K0EmSjyNBs_W",
      "metadata": {},
      "source": [
        "# Count missing data for each column\n",
        "print(titanic.isna().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "VHkhR47k8xdtF3Rm3k9hA",
      "metadata": {},
      "source": [
        "The variables `age`\n",
        ", `deck`\n",
        " and `embark_town`\n",
        " contain multiple missing values. For the current tutorial we will not remove or manipulate these values.\n",
        "### Duplicates\n",
        "Duplicate rows refer to observations that are identical in all their attribute values across all columns and can arise due to reasons such as missing values, data entry errors, system glitches, or issues during data collection. The `duplicated()`\n",
        " function in pandas identifies and marks duplicate rows:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "_996cCY_EM-95DstYtC91",
      "metadata": {},
      "source": [
        "# Count duplicate rows\n",
        "print(titanic.duplicated().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "gYMzQ9JW08jnKOUyLwpHw",
      "metadata": {},
      "source": [
        "The Titanic dataset contains 107 duplicated rows. It's essential to exercise caution when deciding whether to keep or delete duplicates. Some duplicates may result from missing data. For instance, `age`\n",
        " and `deck`\n",
        " variables contain multiple missing observations, so identical rows could still originate from different passengers due to incomplete information. Blindly removing duplicates may result in the loss of valuable data. In this tutorial, we opted not to remove duplicates for this reason.\n",
        "### Outliers\n",
        "Outliers are data points that deviate significantly from the majority of observations in a dataset. Outliers can have a disproportionate impact on statistical measures and modeling results, therefore it's crucial that they are correctly identified and handled.\n",
        "$Z$-scores, also known as standard scores, are a valuable tool for detecting outliers. They quantify how many standard deviations a data point is away from the mean of the dataset. They provide a standardized measure of deviation that is independent of the original data's scale. $Z$-scores are calculated by subtracting the mean of a variable from a specific data point (indicating how far the data point is from the average) and dividing this difference by the standard deviation:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "GlW4rFmYZPysfsGNqEY_I",
      "metadata": {},
      "source": [
        "# Calculate the mean and standard deviation for each numerical column\n",
        "mean_values = numerical_columns.mean()\n",
        "std_values = numerical_columns.std()\n",
        "\n",
        "# Calculate z-scores for each data point in the numerical columns\n",
        "z_scores = (numerical_columns - mean_values) / std_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cjTwKA-S36tXJ6CbFCWJu",
      "metadata": {},
      "source": [
        "A $z$-threshold is set, with $z$-scores greater than or equal to that threshold being considered outliers. The choice of z-threshold depends on the specific analysis and domain knowledge. For the current analysis a threshold of $2$ is used:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "pAdx7s7LeZNQGOdDskI_T",
      "metadata": {},
      "source": [
        "# Define the z-score threshold for identifying outliers\n",
        "z_threshold = 2\n",
        "\n",
        "# Identify and print outliers using z-scores\n",
        "outliers = titanic[abs(z_scores) > z_threshold]\n",
        "\n",
        "# Filter to exclude columns with all NaN values\n",
        "outliers = outliers.dropna(axis=1, how='all')\n",
        "\n",
        "print(outliers.count())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "r2csDKBdHCnLx6r1HAUne",
      "metadata": {},
      "source": [
        "Overall, 29 outliers were identified for the `age`\n",
        " variable and 38 outliers for the `fare`\n",
        " variable. In the current tutorial none of the outliers are removed. \n",
        "<article class=\"message is-info\">\n",
        "  <div class=\"message-header\">Note</div>\n",
        "  <div class=\"message-body\">\n",
        "  \n",
        "  When dealing with higher dimensional, multivariate data the Mahalanobis distance would be used for outlier detection, which calculates the distance between a data point and the center of a dataset, accounting for the correlations between variables.\n",
        "\n",
        "  \n",
        "  </div>\n",
        "</article>\n",
        "\n",
        "## Visualizations\n",
        "While measures like mean, median, mode and standard deviation provide insights into the typical values and spread of data, visualizations offer a more comprehensive understanding by revealing patterns, relationships, and additional information within the dataset. Different data types necessitate the use of specific types of plots. \n",
        "### Histograms\n",
        "A histogram is a graphical representation of the distribution of the data. Histograms are particularly useful for understanding the general tendencies, spread, and shape of data. The `sns.histplot()`\n",
        " function from the Seaborn library is used to plot a histogram of the fare prices paid by the passengers on Titanic: \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "d_uRiy7N-Euh3y_w3Urzu",
      "metadata": {},
      "source": [
        "sns.histplot(titanic['fare'], bins=50, color='skyblue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "q5ZMbrqqwva1-lexV4wwt",
      "metadata": {},
      "source": [
        "In this case, the histogram is positively skewed, as it has an elongated tail on the right side. Overall, the histogram shows us that the majority of passengers paid relatively lower fares, while a small number paid high fares, resulting in the elongated tail. The plot illustrates the findings from the numerical summary, where a skewness value of 5 was observed. This is considered large and indicates that the distribution is heavily skewed to the right. \n",
        "### Box Plots\n",
        "Similarly to histograms, box plots (a.k.a a box-and-whisker plot) are used to visualize the distribution of a variable. Boxplots are particularly useful for comparing the distribution of a variable across different categories or groups. In the cell below we make use of the `sns.boxplot()`\n",
        " function from the Seaborn library, to plot the age of the passengers across different classes in the titanic dataset: \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "xnsFc2hsRiTl7bVI__ogN",
      "metadata": {},
      "source": [
        "# Create a boxplot of the \"fare\" column\n",
        "sns.boxplot(x=titanic['class'], y=titanic['age'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "G9s1-TCu3iRR1prcLNt5O",
      "metadata": {},
      "source": [
        "Each box in the plot represents the age distribution of one of the three passenger classes: First Class (First), Second Class (Second), and Third Class (Third). The vertical position of each box on the y-axis represents the median (50th percentile) age of passengers in that class. The horizontal line inside the box represents the median age. The height of each box shows the interquartile range (IQR), which measures the middle 50% of the age distribution. The vertical lines extending from the boxes are called \"whiskers\" and represent the range of ages that fall within a reasonable quartile range (Quartile 1 – 1.5 * IQR or Quartile 3 + 1.5 * IQR). Any data points beyond the whiskers are considered outliers. The plot above shows that the median age of passengers differs between classes, where the first class of passengers have the highest median age, and third class have the lowest. The second and third classes have multiple outliers, with the second class having outliers on both ends.\n",
        "### Bar Charts\n",
        "Bar charts are used to display the frequency of categories within a dataset. They are useful for comparing different categories and understanding their relative sizes. The cell below makes use of the `sns.barplot()`\n",
        " function from the Seaborn library, to provide a visual representation of the class distribution among the passengers: \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "vQ_ZMmLBUDjFdRMtzhbp4",
      "metadata": {},
      "source": [
        "# Count the number of passengers in each class\n",
        "class_counts = titanic['class'].value_counts()\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values, palette='Set2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "OoGVnihbfK7FIy65kpg49",
      "metadata": {},
      "source": [
        "The third class has the highest number of passengers, while the second class has the lowest. The plot clearly visualizes the class imbalances. \n",
        "### Heatmaps\n",
        "Heatmaps are commonly used to visualize relationships, patterns, or distributions within complex datasets. Heatmaps are particularly useful for identifying multicollinearity. The Seaborn library contains the `sns.heatmap()`\n",
        " function, used in the cell below to create a heatmap of the correlation matrix: \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "1EwGBRRt99M_gy8uJRxvB",
      "metadata": {},
      "source": [
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "mpot6eEJ3qh3X009uGn9Q",
      "metadata": {},
      "source": [
        "Each cell in the heatmap represents the correlation between two numerical variables from the dataset. The color of each cell indicates the strength and direction of the correlation with darker colors indicating stronger, and lighter blue colors indicating weaker or no correlations (close to 0). Blue cells represent negative correlations, while red cells represent positive correlations. The intensity of the color corresponds to the magnitude of the correlation coefficient. The numerical values within the cells provide precise correlation coefficients.\n",
        "### Scatter Plots\n",
        "Scatter plots are used to visualize the relationship between two numerical variables. Sometimes, outliers can be spotted in scatterplots, as they appear as points far away from the remaining parts of the data. In the cell below the `sns.scatterplot()`\n",
        " function from the Seaborn library is used to visualize the relationship between passenger ages and the fare prices paid:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "E7TrRRqpOWvxhLompvOir",
      "metadata": {},
      "source": [
        "sns.scatterplot(x=titanic['age'], y=titanic['fare'], alpha=0.5, color='b')  # Plot age vs. fare"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dj7lAmODvvWx0FUAJ87VC",
      "metadata": {},
      "source": [
        "The scatterplot above shows no discernible pattern or trend between `age`\n",
        " and `fare`\n",
        ", no significant clustering of points is visible, and no clear correlation can be observed, as also indicated by the values of the correlation matrix. \n",
        "### Pair Plots\n",
        "Pair plots are a comprehensive way to visualize the relationships between multiple numerical variables simultaneously. Pair plots can be generated for the `age`\n",
        " and `fare`\n",
        " variables using the `sns.pairplot()`\n",
        " function from the Seaborn library:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "FmeLtREZzqi-HV2t28dDp",
      "metadata": {},
      "source": [
        "sns.pairplot(titanic[['age', 'fare']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "oGUmHDVYUmcnWW2PRcx3C",
      "metadata": {},
      "source": [
        "The plot suggests that there is no correlation between the `age`\n",
        " and `fare`\n",
        " variables. There are distinct patterns in fare distribution (lower right corner), with a concentration of passengers paying lower fares and fewer passengers paying higher fares. \n",
        "### Missing Data Patterns\n",
        "Heatmaps can also provide a quick and intuitive way to identify patterns of missing data. You can create a heatmap of missing data by combining the `sns.heatmap()`\n",
        " function from the seaborn library and the `isna()`\n",
        " function:\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "MwXlIbk05Se-iKBL-kKkr",
      "metadata": {},
      "source": [
        "sns.heatmap(titanic.isna(), cbar=False, cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bqk2Pt6xfWoNQ5Rro9Mvv",
      "metadata": {},
      "source": [
        "The heatmap shows missing values as yellow cells, allowing quick identification of which variables (x-axis) and observations (y-axis) have missing data.\n",
        ""
      ]
    }
  ]
}