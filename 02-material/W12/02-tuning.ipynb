{
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": "py",
      "mimetype": "text/x-python",
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5,
  "cells": [
    {
      "cell_type": "code",
      "id": "css_setup",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        }
      },
      "source": [
        "import requests\n",
        "from IPython.core.display import HTML\n",
        "HTML(f\"\"\"\n",
        "<style>\n",
        "@import \"https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css\";\n",
        "</style>\n",
        "\"\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "WeTcNAESLjnFDPxv7q019",
      "metadata": {},
      "source": [
        "# Model Tuning\n",
        "This exercise is about investigating tehchiques to improve models and avoid overfitting by:\n",
        "- Dropout layer\n",
        "- Early stopping\n",
        "- Data augmentation\n",
        "\n",
        "As mentioned in the [youtube video](//youtu.be/njKP3FqW3Sk?thttps=2807)\n",
        " and the lecture, dropout layers and early stopping are useful methods to constrain the optimisation to counteract overfitting.\n",
        "Like in the first exercise the `PyTorchTrainer`\n",
        " method must be used to set up the training process for the architechtures. The cell below loads the libraries and provides a function for training models.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "HiNDWVX5Ma_febrWlP_lJ",
      "metadata": {},
      "source": [
        "from torch import optim\n",
        "from trainers import PyTorchTrainer\n",
        "from networks import *\n",
        "from torchvision import transforms\n",
        "from fashionmnist_utils.mnist_reader import load_mnist\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Create the 'models' folder\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "# Create the 'runs' folder\n",
        "os.makedirs(\"runs\", exist_ok=True)\n",
        "\n",
        "def train_pytorch_network(to_train, early_stopping=False, patience=5):\n",
        "\n",
        "    transform = transforms.ToTensor() ## simply a conversion from PIL (image format) to torch tensors.\n",
        "    \n",
        "    network = to_train\n",
        "\n",
        "    trainerNetwork = PyTorchTrainer(\n",
        "        nn_module=network,\n",
        "        transform=transform,\n",
        "        optimizer=optim.SGD(network.parameters(), lr=1e-2, momentum=0.5),\n",
        "        batch_size=128,\n",
        "    ) \n",
        "\n",
        "    print(\"training the network started\")\n",
        "    if early_stopping:\n",
        "        trainerNetwork.train_es(30, patience=patience)\n",
        "    else:\n",
        "        trainerNetwork.train(10)\n",
        "    \n",
        "    trainerNetwork.save()\n",
        "    print(\"training and saving the network ended\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "yHRrlwipDRzp1h2dTJuN9",
      "metadata": {},
      "source": [
        "## Dropout Layer\n",
        "In this task you will investigate the dropout layers of the `TopCNN`\n",
        " model defined in the cell below. PyTorch provides the layer [nn.Dropout2d](https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html<elem-3>.nn.Dropout2d)\n",
        " for convolutional layers and [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html<elem-4>.nn.Dropout)\n",
        " for fully connected layers.\n",
        "<article class=\"message task\"><a class=\"anchor\" id=\"dropout\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 1: Dropout layer parameters</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-code\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "1. Run the cell below to train the model.\n",
        "2. Use the code from the NN architectures exercise\n",
        " to plot and evaluate the model performance. \n",
        "3. Experiment with  the probability parameter, `p`\n",
        ",  of the dropout layers and compare the models to determine the best parameter setting for `p`\n",
        ". Start with 0.2, then 0.7. \n",
        "\n",
        "<article class=\"message is-info\">\n",
        "  <div class=\"message-header\">Info</div>\n",
        "  <div class=\"message-body\">\n",
        "\n",
        "  Training of this model takes several minutes, depending on your computer.\n",
        "\n",
        "\n",
        "  </div>\n",
        "</article>\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "qGia7b6onnq3hQLWS-S09",
      "metadata": {},
      "source": [
        "class TopCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_1 = nn.Conv2d(1, 32, kernel_size=9, padding=4)\n",
        "        self.bn_1 = nn.BatchNorm2d(32)\n",
        "        self.conv_2 = nn.Conv2d(32, 32, kernel_size=5, padding=2)\n",
        "        self.bn_2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.drop_1 = nn.Dropout2d(p=0.5)\n",
        "\n",
        "        self.conv_3 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.bn_3 = nn.BatchNorm2d(64)\n",
        "        self.conv_4 = nn.Conv2d(64, 64, kernel_size=3)\n",
        "        self.bn_4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.drop_2 = nn.Dropout2d(p=0.5)\n",
        "\n",
        "        self.linear_1 = nn.Linear(5 ** 2 * 64, 100)\n",
        "\n",
        "        self.drop_3 = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.linear_2 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = self.bn_1(x)\n",
        "        x = F.relu(self.conv_2(x))\n",
        "        x = self.bn_2(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.drop_1(x)\n",
        "\n",
        "        x = F.relu(self.conv_3(x))\n",
        "        x = self.bn_3(x)\n",
        "        x = F.relu(self.conv_4(x))\n",
        "        x = self.bn_4(x)\n",
        "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "        x = self.drop_2(x)\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "        x = self.linear_1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.drop_3(x)\n",
        "\n",
        "        x = self.linear_2(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "train_pytorch_network(TopCNN())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "pp8ccIiGYnVVxNTzmzyOj",
      "metadata": {},
      "source": [
        "<article class=\"message task\"><a class=\"anchor\" id=\"dropout2\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 2: Adding a dropout layer</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-code\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "1. Add a dropout layer to the `CNN4layer`\n",
        " model defined in the cell below. \n",
        "2. Compare model performance with and without the dropout layer.\n",
        "3. Reflect on  how the performance achieved above compares to the `TopCNN`\n",
        " model.\n",
        "\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "8lsZi7yn2VZsMQRO35VEo",
      "metadata": {},
      "source": [
        "class CNN4Layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
        "        self.conv_3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "        self.conv_4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.layer_1 = nn.Linear(in_features=16 * 32, out_features=80)\n",
        "        self.layer_2 = nn.Linear(in_features=80, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, picture):\n",
        "        # 1 image is given, 8 output channels , kernel size 3\n",
        "        imageConv1 = F.relu(self.conv_1(picture)) \n",
        "        # 8 images is given, 16 channels out, kernel size 3\n",
        "        imageConv2 = F.relu(self.conv_2(imageConv1)) \n",
        "        # divides the imagesize by 2, image size = 4 \n",
        "        maxPool2 = F.max_pool2d(imageConv2, 2, 2 )  \n",
        "         # 8 images is given, 16 channels, kernel size 3\n",
        "        imageConv3 = F.relu(self.conv_3(maxPool2)) \n",
        "        # 8 images is given, 16 comes out, kernel size 3\n",
        "        imageConv3 = F.relu(self.conv_4(imageConv3))  \n",
        "        maxPool4 = F.max_pool2d(imageConv3, 2, 2)\n",
        "        imageFlatten = torch.flatten(maxPool4, start_dim=1)\n",
        "        linearImage1 = F.relu(self.layer_1(imageFlatten))\n",
        "        return self.layer_2(linearImage1)\n",
        "\n",
        "train_pytorch_network(CNN4Layer())\n",
        "\n",
        "# write your solution here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "EBKEvcwQ_CNPOiy5Xye8b",
      "metadata": {},
      "source": [
        "## Early stopping\n",
        "This exercises is about early stopping using the `CNN4Layer`\n",
        " model. \n",
        "<article class=\"message task\"><a class=\"anchor\" id=\"early_stopping\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 3: Early stopping</span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-code\"></i><i class=\"bi bi-stoplights easy\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "1. Execute the cell below to run the training process with early stopping. \n",
        "2. Change the `patience`\n",
        " parameter and observe how it changes the training time. Try 3 and 5 as the parameter values.\n",
        "3. What is the influence of changing the patience parameter, and explain why.\n",
        "4. Use the previous exercises to visualize the model results and compare its performance with the previous models. Explain how and why dropout and early stopping influence classification performance?\n",
        "\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "Ge9ggELTbK4RK-uT0rIK6",
      "metadata": {},
      "source": [
        "train_pytorch_network(CNN4Layer_dropout(),True, patience=1)\n",
        "\n",
        "# write your solution here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "kgzOmGVDpt648HDBxTHPQ",
      "metadata": {},
      "source": [
        "## Data Augmentation\n",
        "In this exercise you will implement data augmentation using PyTorch's `torchvision`\n",
        " library. Data augmentation involves subjecting the current training batch data to random transformations, effectively creating new training samples. \n",
        "The `train_pytorch_network`\n",
        " function (defined in the first cell) already contains the methods to transform the input images (in PIL format) to PyTorch tensors. Your task is to modify the function and add new augmentations to the transformation. \n",
        "The [torchvision.transforms.Compose](https://pytorch.org/vision/stable/transforms.html?highlight=compose<elem-14>.transforms.Compose)\n",
        " method allows you to compose multiple transformations. The function [torchvision.transforms.RandomAffine](https://pytorch.org/vision/stable/transforms.html<elem-15>.transforms.RandomAffine)\n",
        " allows you to randomly subject the training data to affine transformations. Each transformation must end with `transforms.ToTensors`\n",
        " function. For example:\n",
        "```python3\n",
        "transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomAffine(45),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "\n",
        "```\n",
        "<article class=\"message task\"><a class=\"anchor\" id=\"augmentation\"></a>\n",
        "    <div class=\"message-header\">\n",
        "        <span>Task 4: Data augmentation <em>(optional)</em></span>\n",
        "        <span class=\"has-text-right\">\n",
        "          <i class=\"bi bi-code\"></i><i class=\"bi bi-stoplights medium\"></i>\n",
        "        </span>\n",
        "    </div>\n",
        "<div class=\"message-body\">\n",
        "\n",
        "\n",
        "1. Subject the training data to random affine transformations then train the `TopCNN`\n",
        " and `CNN4layer`\n",
        " models by following these steps:\n",
        "\n",
        "- Compile a transformation object in `train_pytorch_network`\n",
        " using the `RandomAffine`\n",
        ".\n",
        "- Train the `TopCNN`\n",
        " and `CNN4layer`\n",
        " networks .\n",
        "- Experiment with adding other types of data augmentation as well. \n",
        "\n",
        "2. Refelect on how data augmentation impacts the results and the training. Support your arguments with figures.\n",
        "\n",
        "\n",
        "\n",
        "</div></article>\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "2EFov6B0KazkTdtItheaR",
      "metadata": {},
      "source": [
        "def train_pytorch_network(to_train, early_stopping=False, patience=5):\n",
        "\n",
        "    transform = transforms.ToTensor() ## simply a conversion from PIL (image format) to torch tensors\n",
        "    \n",
        "    network = to_train\n",
        "\n",
        "    trainerNetwork = PyTorchTrainer(\n",
        "        nn_module=network,\n",
        "        transform=transform,\n",
        "        optimizer=optim.SGD(network.parameters(), lr=1e-2, momentum=0.5),\n",
        "        batch_size=128,\n",
        "    ) \n",
        "\n",
        "    print(\"training the network started\")\n",
        "    if early_stopping:\n",
        "        trainerNetwork.train_es(30, patience=patience)\n",
        "    else:\n",
        "        trainerNetwork.train(10)\n",
        "    \n",
        "    trainerNetwork.save()\n",
        "    print(\"training the network ended\")\n",
        "    \n",
        "# write your solution here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6oOwhPuy19_Vb07K5TmA6",
      "metadata": {},
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "id": "o4PihasbvOTpwMDSnsWWB",
      "metadata": {},
      "source": [
        "# write reflections here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "WmRuqOGgcFD0A2jHsMeJ-",
      "metadata": {},
      "source": [
        ""
      ]
    }
  ]
}